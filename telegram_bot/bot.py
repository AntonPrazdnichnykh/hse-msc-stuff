import telebot
import config
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from natasha import Doc, Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger
from deeppavlov import configs, build_model
from parse.recipe_parser import RecipeParser
from parse.user import User

bot = telebot.TeleBot(config.BOT_TOKEN)

tokenizer_tox = AutoTokenizer.from_pretrained("sismetanin/rubert-toxic-pikabu-2ch")
toxic_model = AutoModelForSequenceClassification.from_pretrained("sismetanin/rubert-toxic-pikabu-2ch")
ner_model = build_model(configs.ner.ner_ontonotes_bert_mult, download=True)

user_dict = {}

recipe_parser = RecipeParser()

segmenter = Segmenter()
emb = NewsEmbedding()
morph_tagger = NewsMorphTagger(emb)
morph_vocab = MorphVocab()


@bot.message_handler(commands=['start'])  # –§—É–Ω–∫—Ü–∏—è –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –∫–æ–º–∞–Ω–¥—É 'start'
def start_message(message):
    bot.send_message(message.chat.id,
                 f"–ü—Ä–∏–≤–µ—Ç!\n"
                 f"–í–≤–µ–¥–∏ —Å–ø–∏—Å–æ–∫ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤, –∏ —è –ø–æ–¥—Å–∫–∞–∂—É —Ç–µ–±–µ, —á—Ç–æ –º–æ–∂–Ω–æ –∏–∑ –Ω–∏—Ö –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—åÔ∏èüçù\n\n"
                 f"–ß—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥, –Ω–∞–ø–∏—à–∏ /help \n"
                 f"–ß—Ç–æ–±—ã –∑–∞–∫–æ–Ω—á–∏—Ç—å –¥–∏–∞–ª–æ–≥, –Ω–∞–ø–∏—à–∏ /exit\n",
                 parse_mode='HTML')


@bot.message_handler(commands=['help'])  # –§—É–Ω–∫—Ü–∏—è –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –∫–æ–º–∞–Ω–¥—É 'help'
def help_message(message):
    bot.send_message(message.chat.id,
                 f"<b>–Ø –∑–Ω–∞—é —Å–ª–µ–¥—É—é—â–∏–µ –∫–æ–º–∞–Ω–¥—ã</b>:\n\n"
                 f"/help - <i>–ü–æ–≤—Ç–æ—Ä–∏—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ</i>\n\n"
                 f"/exit - <i>–í—ã—Ö–æ–¥</i>\n\n"
                 f"–ï—Å–ª–∏ —Ö–æ—á–µ—à—å —É–∑–Ω–∞—Ç—å, —á—Ç–æ –º–æ–∂–Ω–æ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ -- –Ω–∞–ø–∏—à–∏, —è —Ç–µ–±—è –ø–æ–π–º—É!",
                 parse_mode='HTML')


@bot.message_handler(commands=['exit'])  # –§—É–Ω–∫—Ü–∏—è –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –∫–æ–º–∞–Ω–¥—É 'exit'
def end_message(message):
    user_dict[message.chat.id].needs_greet = True
    bot.send_message(message.chat.id,
                     f"–†–∞–¥ –±—ã–ª –ø–æ–º–æ—á—å! –î–æ –≤—Å—Ç—Ä–µ—á–∏!\n")


def is_toxic(message):
    message = Doc(message.text)
    message.segment(segmenter)
    message.tag_morph(morph_tagger)
    for token in message.tokens:
        token.lemmatize(morph_vocab)
    tokens_pt = tokenizer_tox(message.text, return_tensors="pt")
    with torch.no_grad():
        pred = torch.nn.functional.softmax(toxic_model(**tokens_pt)[0], dim=1).squeeze()
        request_is_toxic = pred[1] > 0.8
        return request_is_toxic


def is_appology(message):
    message = Doc(message.text)
    message.segment(segmenter)
    message.tag_morph(morph_tagger)
    cnt = 0
    for token in message.tokens:
        token.lemmatize(morph_vocab)
        if token.lemma.lower() in ['–∏–∑–≤–∏–Ω–∏—Ç—å', '–∏–∑–≤–∏–Ω–µ–Ω–∏–µ', '–ø—Ä–æ—Å—Ç–∏—Ç—å', '–ø—Ä–æ—â–µ–Ω–∏–µ', '–∏–∑–≤–∏–Ω–∏']:
            cnt += 1
    return cnt


def is_bye(message):
    message = Doc(message.text)
    message.segment(segmenter)
    message.tag_morph(morph_tagger)
    cnt = 0
    for token in message.tokens:
        token.lemmatize(morph_vocab)
        if token.lemma.lower() in ['–ø–æ–∫–∞', '—Å–≤–∏–¥–∞–Ω–∏–µ']:
            cnt += 1
    return cnt


@bot.message_handler(content_types=['text'])  # –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
def get_text(message):
    chat_id = message.chat.id
    tox = is_toxic(message)
    if tox:
        if chat_id in user_dict:
            user_dict[chat_id].toxic = tox
        else:
            user_dict[chat_id] = User(tox)
        bot.reply_to(message,
                    f"–ù—É –Ω–µ—Ç, —Ç–∞–∫ –¥–µ–ª–∞ –Ω–µ –¥–µ–ª–∞—é—Ç—Å—è.\n\n"
                    f"–ù–µ –±—É–¥—É –≤–∞–º –ø–æ–º–æ–≥–∞—Ç—å, –ø–æ–∫–∞ –Ω–µ –∏–∑–≤–∏–Ω–∏—Ç–µ—Å—å."
                    )
        # bot.register_next_step_handler(msg, get_text)
        return

    if chat_id in user_dict and user_dict[chat_id].toxic:
        if is_appology(message):
            bot.reply_to(message, "–í–∞—à–∏ –∏–∑–≤–∏–Ω–µ–Ω–∏—è –ø—Ä–∏–Ω—è—Ç—ã! –¢–µ–ø–µ—Ä—å –º–æ–∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞–Ω–∏—è —Ä–µ—Ü–µ–ø—Ç–æ–≤ —Å–Ω–æ–≤–∞ –≤ –≤–∞—à–µ–º "
                                  "—Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏!")
            user_dict[chat_id].toxic = 0
        else:
            bot.reply_to(message, "–Ø –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –∂–¥—É –≤–∞—à–∏—Ö –∏–∑–≤–∏–Ω–µ–Ω–∏–π...")
        # bot.register_next_step_handler(msg, get_text)
        return
    if chat_id not in user_dict:
        user_dict[chat_id] = User(tox)
    if is_bye(message):
        user_dict[chat_id].needs_greet = True
        bot.send_message(chat_id, "–†–∞–¥ –±—ã–ª–∞ –ø–æ–º–æ—á—å! –î–æ –≤—Å—Ç—Ä–µ—á–∏!")
        return
    if user_dict[chat_id].needs_greet:
        user_dict[chat_id].needs_greet = False
        bot.send_message(chat_id, "–ü—Ä–∏–≤–µ—Ç–∏–∫–∏-–ø–∏—Å—Ç–æ–ª–µ—Ç–∏–∫–∏!")
        return

    # query classification
    recipe_cnt = 0
    doc = Doc(message.text)
    doc.segment(segmenter)
    doc.tag_morph(morph_tagger)
    for token in doc.tokens:
        token.lemmatize(morph_vocab)
        if token.lemma in recipe_parser.keywords:
            recipe_cnt += 1

    if recipe_cnt == 0:
        bot.reply_to(message, '–ö–∞–∂–µ—Ç—Å—è, —è –Ω–µ –ø–æ–Ω—è–ª, —á—Ç–æ –≤—ã –æ—Ç –º–µ–Ω—è —Ö–æ—Ç–∏—Ç–µ((((\n'
                              '–Ø –ø–æ–∫–∞ —É–º–µ—é —Ç–æ–ª—å–∫–æ —Ä–µ—Ü–µ–ø—Ç—ã –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å.')
        return
    bot.reply_to(message, '–ú–æ–≥—É –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —Ç–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç–∏–∫:')
    process_recipe_step(message)


def process_recipe_step(message):
    chat_id = message.chat.id
    recipe_ingredients = recipe_parser._extract_ingredients(Doc(message.text))
    if len(recipe_ingredients) == 0:
        bot.reply_to(message, '–Ø –Ω–µ –∑–Ω–∞—é —Ç–∞–∫–∏—Ö –∏–Ω–≥—Ä–∏–¥–∏–µ–Ω—Ç–æ–≤(((\n–°–ø—Ä–æ—Å–∏—Ç–µ –º–µ–Ω—è —Ä–µ—Ü–µ–ø—Ç –∏–∑ —á–µ–≥–æ-–Ω–∏–±—É–¥—å –¥—Ä—É–≥–æ–≥–æ.')
        # bot.register_next_step_handler(msg, get_text)
    else:
        recipe = recipe_parser.process(recipe_ingredients)
        if recipe is None:
            bot.reply_to(message, '–ú–Ω–µ –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ä–µ—Ü–µ–ø—Ç–∞ –∏–∑ —É–∫–∞–∑–∞–Ω—ã—Ö –≤–∞–º–∏ –∏–Ω–≥—Ä–∏–¥–∏–µ–Ω—Ç–æ–≤((('
                                  '\n–°–ø—Ä–æ—Å–∏—Ç–µ –º–µ–Ω—è —Ä–µ—Ü–µ–ø—Ç –∏–∑ —á–µ–≥–æ-–Ω–∏–±—É–¥—å –¥—Ä—É–≥–æ–≥–æ.')
            # bot.register_next_step_handler(msg, get_text)
        else:
            out_msg = format_recipe(recipe)
            bot.reply_to(message, out_msg, parse_mode='HTML')
            bot.send_message(chat_id,
                             text='–Ø –º–æ–≥—É –µ—â–µ —á–µ–º-—Ç–æ –ø–æ–º–æ—á—å?\n–ï—Å–ª–∏ –Ω–µ—Ç, —Ç–æ –ø–æ–ø—Ä–æ—â–∞–π—Å—è —Å–æ –º–Ω–æ–π –∏–ª–∏ –Ω–∞–ø–∏—à–∏ /exit')
            # bot.register_next_step_handler(msg, get_text)


def format_recipe(recipe):
    out = f"<b>–ù–∞–∑–≤–∞–Ω–∏–µ –±–ª—é–¥–∞: {recipe['name']}</b>\n\n<b>–í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–Ω–≥—Ä–∏–¥–∏–µ–Ω—Ç—ã:</b>\n\n"
    for ingredient in recipe['ingredients']:
        out += f"{ingredient}\n"
    out += f"\n\n<b>–®–∞–≥–∏ –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è:</b>\n\n"
    for i, step in enumerate(recipe['steps']):
        out += f"–®–∞–≥ {i+1}:\n{step}\n\n"
    return out


bot.polling(none_stop=True, interval=0)
